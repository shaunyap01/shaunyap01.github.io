<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Projects | Shaun Yap</title>
<meta name="keywords" content="">
<meta name="description" content="Some of Shaun&#39;s Projects">
<meta name="author" content="Shaun Yap">
<link rel="canonical" href="https://shaunyap01.github.io/projects/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.3fc93563987a6232a5b8b3e0a25a366c767e125a9f29a8d5ff271f363f5ca833.css" integrity="sha256-P8k1Y5h6YjKluLPgolo2bHZ&#43;ElqfKajV/ycfNj9cqDM=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://shaunyap01.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://shaunyap01.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://shaunyap01.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://shaunyap01.github.io/apple-touch-icon.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="https://shaunyap01.github.io/projects/index.xml">
<link rel="alternate" hreflang="en" href="https://shaunyap01.github.io/projects/">
<meta property="og:title" content="Projects" />
<meta property="og:description" content="Some of Shaun&#39;s Projects" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://shaunyap01.github.io/projects/" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Projects"/>
<meta name="twitter:description" content="Some of Shaun&#39;s Projects"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Projects",
      "item": "https://shaunyap01.github.io/projects/"
    }
  ]
}
</script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" integrity="sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js" integrity="sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          delimiters: [
            {left: '$$', right: '$$', display: true},
            {left: '$', right: '$', display: false},
            {left: "\\begin{equation}", right: "\\end{equation}", display: true},
            {left: "\\begin{equation*}", right: "\\end{equation*}", display: true},
            {left: "\\begin{align}", right: "\\end{align}", display: true},
            {left: "\\begin{align*}", right: "\\end{align*}", display: true},
            {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
            {left: "\\begin{gather}", right: "\\end{gather}", display: true},
            {left: "\\begin{CD}", right: "\\end{CD}", display: true},
          ],
          throwOnError : false
        });
    });
</script>
 


</head>

<body class="list" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://shaunyap01.github.io/" accesskey="h">
                <img src="https://shaunyap01.github.io/favicon.ico" alt="logo" aria-label="logo"
                    height="18"
                    width="18">Shaun Yap</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://shaunyap01.github.io/research/">
                    <span>Research</span>
                </a>
            </li>
            <li>
                <a href="https://shaunyap01.github.io/articles/">
                    <span>Articles</span>
                </a>
            </li>
            <li>
                <a href="https://shaunyap01.github.io/projects/">
                    <span class="active">Projects</span>
                </a>
            </li>
            <li>
                <a href="https://shaunyap01.github.io/tags/">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://shaunyap01.github.io/archive/">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://shaunyap01.github.io/contact/">
                    <span>Contact</span>
                </a>
            </li>
            <li>
                <a href="https://shaunyap01.github.io/cv.pdf">
                    <span>Curriculum Vitae (CV)</span>
                </a>
            </li>
        </ul>
    </nav>
</header>

    <main class="main"> 
<header class="page-header">
  <h1>
  </h1>
</header>
<div class="post-content"><blockquote>
<p>It is a capital mistake to theorize before one has data. Insensibly one begins to twist facts to suit theories, instead of theories to suit facts.</p>
<p>&ndash; <em>Sherlock Holmes</em>, <em>&ldquo;A Scandal in Bohemia&rdquo;</em></p></blockquote>

</div>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">PGA Tour Stats Scraper
    </h2>
  </header>
  <div class="entry-content">
    <p>This project centres on building a fully automated web scraper that collects tournament-level statistics from the official PGA Tour website, covering data from 2004 to the present. It overcomes the platform’s manual, one-stat-at-a-time download limitation by enabling users to extract structured, high-quality .csv datasets across any year or date range - with support for all available stat codes. The tool is available as both a Python script and an interactive Jupyter Notebook, and the repository also includes a complete pre-scraped dataset (2004–2025) for immediate use.</p>
  </div>
  <footer class="entry-footer"><span title='2025-05-11 00:00:00 +0000 UTC'>11 May 2025</span>&nbsp;&middot;&nbsp;Shaun Yap</footer>
  <a class="entry-link" aria-label="post link to PGA Tour Stats Scraper" href="https://shaunyap01.github.io/projects/pga-tour-stats-scraper/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Evaluating Environment &amp; Climate Truthfulness in Social Media using Deep Learning &amp; Large Language Models (LLMs)
    </h2>
  </header>
  <div class="entry-content">
    <p>Awarded Best Dissertation in Cohort, this MSc project explores the detection of climate and environmental misinformation on social media using a comparative framework of traditional natural language processing techniques, deep learning, and Large Language Models (LLMs). Leveraging a web-scraped dataset from PolitiFact, the study highlights the superiority of CNNs trained on ordinal truthfulness data, with accuracy boosted from 80.1% to 84.0% through GPT-4o-driven feature augmentation. While LLMs enhanced contextual understanding and sentiment analysis, their time complexity posed practical limitations. The project contributes novel insights into model performance trade-offs, evaluation metrics tailored to ordinal classification, and the practical integration of LLMs for misinformation mitigation in climate discourse.</p>
  </div>
  <footer class="entry-footer"><span title='2024-09-01 00:00:00 +0000 UTC'>01 September 2024</span>&nbsp;&middot;&nbsp;Shaun Yap</footer>
  <a class="entry-link" aria-label="post link to Evaluating Environment & Climate Truthfulness in Social Media using Deep Learning & Large Language Models (LLMs)" href="https://shaunyap01.github.io/projects/evaluating-environment-and-climate-truthfulness-in-social-media-using-deep-learning-and-large-language-models/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Kaggle Competition - Flood Prediction EDA
    </h2>
  </header>
  <div class="entry-content">
    <p>Rigorous exploratory analysis of a large-scale (&gt;1,000,000 training datapoints) Kaggle flood prediction dataset. It highlights strong skills in handling high-dimensional structured data, performing scalable EDA with efficient visualisations, and applying both statistical and machine learning techniques for insight generation. Key competencies include dimensionality reduction (PCA, UMAP, t-SNE), correlation analysis, feature distribution comparison, and model interpretation using scikit-learn and statsmodels. The project also showcases custom cross-validation tooling, effective use of pipelines for reproducible modelling, and the derivation of a simplified additive model, reflecting a deep understanding of linear structures in high-volume data.</p>
  </div>
  <footer class="entry-footer"><span title='2024-05-03 00:00:00 +0000 UTC'>03 May 2024</span>&nbsp;&middot;&nbsp;Shaun Yap</footer>
  <a class="entry-link" aria-label="post link to Kaggle Competition - Flood Prediction EDA" href="https://shaunyap01.github.io/projects/kaggle-competition-flood-prediction-eda/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Bayesian Inference
    </h2>
  </header>
  <div class="entry-content">
    <p>This project demonstrates advanced skills in Bayesian hierarchical modelling, data visualisation, and statistical inference using R and JAGS. It showcases the ability to preprocess real-world epidemiological data, implement and diagnose MCMC simulations using Gibbs sampling, and interpret convergence diagnostics (e.g., traceplots, Gelman-Rubin statistics, and autocorrelation). The work highlights proficiency in quantifying uncertainty, leveraging shrinkage effects, and adapting models for updated demographic data. It also reflects strong analytical thinking in comparing posterior estimates across population strata, critically evaluating prior influence, and effectively communicating results through both code and narrative-skills essential for rigorous, reproducible, and insightful statistical analysis.</p>
  </div>
  <footer class="entry-footer"><span title='2024-02-05 00:00:00 +0000 UTC'>05 February 2024</span>&nbsp;&middot;&nbsp;Shaun Yap</footer>
  <a class="entry-link" aria-label="post link to Bayesian Inference" href="https://shaunyap01.github.io/projects/bayesian-inference/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Clustering Countries
    </h2>
  </header>
  <div class="entry-content">
    <p>This project showcases advanced data science and statistical analysis skills through a comprehensive clustering analysis of country-level socio-economic and health data using both hierarchical and k-means clustering methods. Key skills demonstrated include robust data preprocessing, detailed exploratory data analysis with insightful visualisations, Z-score standardisation, PCA for dimensionality reduction, and effective interpretation of cluster structures. The analysis incorporates evaluation metrics such as silhouette and Calinski-Harabasz scores for optimal cluster selection, uses distance metrics (Manhattan and Euclidean), and applies cluster-based inference to identify countries in need of development aid. Additionally, the project integrates model application to new data, creating a prioritised aid strategy using PCA projections and quantitative scoring.</p>
  </div>
  <footer class="entry-footer"><span title='2024-01-10 00:00:00 +0000 UTC'>10 January 2024</span>&nbsp;&middot;&nbsp;Shaun Yap</footer>
  <a class="entry-link" aria-label="post link to Clustering Countries" href="https://shaunyap01.github.io/projects/clustering-countries/"></a>
</article>
    </main>
    

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
</body>
</html>
