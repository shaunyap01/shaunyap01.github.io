<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Projects on Shaun Yap</title>
    <link>https://shaunyap01.github.io/projects/</link>
    <description>Recent content in Projects on Shaun Yap</description>
    <generator>Hugo -- 0.145.0</generator>
    <language>en</language>
    <lastBuildDate>Sun, 11 May 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://shaunyap01.github.io/projects/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>PGA Tour Stats Scraper</title>
      <link>https://shaunyap01.github.io/projects/pga-tour-stats-scrape/</link>
      <pubDate>Sun, 11 May 2025 00:00:00 +0000</pubDate>
      <guid>https://shaunyap01.github.io/projects/pga-tour-stats-scrape/</guid>
      <description>Automate PGA Tour data collection with a Python scraper that extracts tournament-level stats from 2004 to present. Includes full dataset and Jupyter Notebook for analysis.</description>
    </item>
    <item>
      <title>Evaluating Environment &amp; Climate Truthfulness in Social Media using Deep Learning &amp; Large Language Models (LLMs)</title>
      <link>https://shaunyap01.github.io/projects/evaluating-environment-and-climate-truthfulness-in-social-media-using-deep-learning-and-large-language-models/</link>
      <pubDate>Sun, 01 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://shaunyap01.github.io/projects/evaluating-environment-and-climate-truthfulness-in-social-media-using-deep-learning-and-large-language-models/</guid>
      <description>Awarded Best Dissertation in Cohort, this MSc project explores the detection of climate and environmental misinformation on social media using a comparative framework of traditional natural language processing techniques, deep learning, and Large Language Models (LLMs). Leveraging a web-scraped dataset from PolitiFact, the study highlights the superiority of CNNs trained on ordinal truthfulness data, with accuracy boosted from 80.1% to 84.0% through GPT-4o-driven feature augmentation. While LLMs enhanced contextual understanding and sentiment analysis, their time complexity posed practical limitations. The project contributes novel insights into model performance trade-offs, evaluation metrics tailored to ordinal classification, and the practical integration of LLMs for misinformation mitigation in climate discourse.</description>
    </item>
    <item>
      <title>Kaggle Competition - Flood Prediction EDA</title>
      <link>https://shaunyap01.github.io/projects/kaggle-competition-flood-prediction-eda/</link>
      <pubDate>Fri, 03 May 2024 00:00:00 +0000</pubDate>
      <guid>https://shaunyap01.github.io/projects/kaggle-competition-flood-prediction-eda/</guid>
      <description>Rigorous exploratory analysis of a large-scale (&amp;gt;1,000,000 training datapoints) Kaggle flood prediction dataset. It highlights strong skills in handling high-dimensional structured data, performing scalable EDA with efficient visualisations, and applying both statistical and machine learning techniques for insight generation. Key competencies include dimensionality reduction (PCA, UMAP, t-SNE), correlation analysis, feature distribution comparison, and model interpretation using scikit-learn and statsmodels. The project also showcases custom cross-validation tooling, effective use of pipelines for reproducible modelling, and the derivation of a simplified additive model, reflecting a deep understanding of linear structures in high-volume data.</description>
    </item>
    <item>
      <title>Bayesian Inference</title>
      <link>https://shaunyap01.github.io/projects/bayesian-inference/</link>
      <pubDate>Mon, 05 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://shaunyap01.github.io/projects/bayesian-inference/</guid>
      <description>This project demonstrates advanced skills in Bayesian hierarchical modelling, data visualisation, and statistical inference using R and JAGS. It showcases the ability to preprocess real-world epidemiological data, implement and diagnose MCMC simulations using Gibbs sampling, and interpret convergence diagnostics (e.g., traceplots, Gelman-Rubin statistics, and autocorrelation). The work highlights proficiency in quantifying uncertainty, leveraging shrinkage effects, and adapting models for updated demographic data. It also reflects strong analytical thinking in comparing posterior estimates across population strata, critically evaluating prior influence, and effectively communicating results through both code and narrative-skills essential for rigorous, reproducible, and insightful statistical analysis.</description>
    </item>
    <item>
      <title>Clustering Countries</title>
      <link>https://shaunyap01.github.io/projects/clustering-countries/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://shaunyap01.github.io/projects/clustering-countries/</guid>
      <description>This project showcases advanced data science and statistical analysis skills through a comprehensive clustering analysis of country-level socio-economic and health data using both hierarchical and k-means clustering methods. Key skills demonstrated include robust data preprocessing, detailed exploratory data analysis with insightful visualisations, Z-score standardisation, PCA for dimensionality reduction, and effective interpretation of cluster structures. The analysis incorporates evaluation metrics such as silhouette and Calinski-Harabasz scores for optimal cluster selection, uses distance metrics (Manhattan and Euclidean), and applies cluster-based inference to identify countries in need of development aid. Additionally, the project integrates model application to new data, creating a prioritised aid strategy using PCA projections and quantitative scoring.</description>
    </item>
  </channel>
</rss>
