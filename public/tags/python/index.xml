<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>`Python on Shaun Yap</title>
    <link>https://shaunyap01.github.io/tags/python/</link>
    <description>Recent content in `Python on Shaun Yap</description>
    <generator>Hugo -- 0.145.0</generator>
    <language>en</language>
    <lastBuildDate>Sat, 05 Apr 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://shaunyap01.github.io/tags/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Understanding Trump&#39;s Tariff Formula</title>
      <link>https://shaunyap01.github.io/articles/trump-tariff-equation/</link>
      <pubDate>Sat, 05 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://shaunyap01.github.io/articles/trump-tariff-equation/</guid>
      <description>On April 2, 2025, President Donald Trump declared &amp;#39;Liberation Day&amp;#39;, unveiling aggressive new tariffs designed to correct trade imbalances via a controversial formula from the U.S. Trade Representative (USTR). This tariff equation, which aims to achieve a bilateral trade balance of zero, adjusts rates based on export-import disparities, elasticity of demand, and tariff passthrough. This article focuses on explaining the Trump Tariff formula to all with worked examples and offering Python tools to replicate and validate the data.</description>
    </item>
    <item>
      <title>Evaluating Environment &amp; Climate Truthfulness in Social Media using Deep Learning &amp; Large Language Models (LLMs)</title>
      <link>https://shaunyap01.github.io/projects/evaluating-environment-and-climate-truthfulness-in-social-media-using-deep-learning-and-large-language-models/</link>
      <pubDate>Sun, 01 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://shaunyap01.github.io/projects/evaluating-environment-and-climate-truthfulness-in-social-media-using-deep-learning-and-large-language-models/</guid>
      <description>Awarded Best Dissertation in Cohort, this MSc project explores the detection of climate and environmental misinformation on social media using a comparative framework of traditional natural language processing techniques, deep learning, and Large Language Models (LLMs). Leveraging a web-scraped dataset from PolitiFact, the study highlights the superiority of CNNs trained on ordinal truthfulness data, with accuracy boosted from 80.1% to 84.0% through GPT-4o-driven feature augmentation. While LLMs enhanced contextual understanding and sentiment analysis, their time complexity posed practical limitations. The project contributes novel insights into model performance trade-offs, evaluation metrics tailored to ordinal classification, and the practical integration of LLMs for misinformation mitigation in climate discourse.</description>
    </item>
    <item>
      <title>Kaggle Competition - Flood Prediction EDA</title>
      <link>https://shaunyap01.github.io/projects/kaggle-competition-flood-prediction-eda/</link>
      <pubDate>Fri, 03 May 2024 00:00:00 +0000</pubDate>
      <guid>https://shaunyap01.github.io/projects/kaggle-competition-flood-prediction-eda/</guid>
      <description>Rigorous exploratory analysis of a large-scale (&amp;gt;1,000,000 training datapoints) Kaggle flood prediction dataset. It highlights strong skills in handling high-dimensional structured data, performing scalable EDA with efficient visualisations, and applying both statistical and machine learning techniques for insight generation. Key competencies include dimensionality reduction (PCA, UMAP, t-SNE), correlation analysis, feature distribution comparison, and model interpretation using scikit-learn and statsmodels. The project also showcases custom cross-validation tooling, effective use of pipelines for reproducible modelling, and the derivation of a simplified additive model, reflecting a deep understanding of linear structures in high-volume data.</description>
    </item>
    <item>
      <title>Clustering Countries</title>
      <link>https://shaunyap01.github.io/projects/clustering-countries/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://shaunyap01.github.io/projects/clustering-countries/</guid>
      <description>This project showcases advanced data science and statistical analysis skills through a comprehensive clustering analysis of country-level socio-economic and health data using both hierarchical and k-means clustering methods. Key skills demonstrated include robust data preprocessing, detailed exploratory data analysis with insightful visualisations, Z-score standardisation, PCA for dimensionality reduction, and effective interpretation of cluster structures. The analysis incorporates evaluation metrics such as silhouette and Calinski-Harabasz scores for optimal cluster selection, uses distance metrics (Manhattan and Euclidean), and applies cluster-based inference to identify countries in need of development aid. Additionally, the project integrates model application to new data, creating a prioritised aid strategy using PCA projections and quantitative scoring.</description>
    </item>
  </channel>
</rss>
